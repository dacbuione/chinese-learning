import React, { useState, useEffect } from 'react';
import { View, TouchableOpacity, StyleSheet, Animated, Text, Alert } from 'react-native';
import { useEnhancedNativeSpeech, NativeSpeechConfig, SpeechResult } from '../../../hooks/useEnhancedNativeSpeech';
import { colors, getResponsiveSpacing, getResponsiveFontSize, Layout } from '../../../theme';

interface NativeSpeechButtonProps {
  expectedText: string;
  onResult: (result: SpeechResult & { accuracy: number }) => void;
  onError: (error: string) => void;
  disabled?: boolean;
  language?: 'zh-CN' | 'zh-TW' | 'en-US';
}

export const NativeSpeechButton: React.FC<NativeSpeechButtonProps> = ({
  expectedText,
  onResult,
  onError,
  disabled = false,
  language = 'zh-CN'
}) => {
  const {
    transcript,
    partialTranscript,
    isListening,
    error,
    hasPermission,
    isAvailable,
    isExpoGo,
    recognizeForDuration,
    checkAvailability
  } = useEnhancedNativeSpeech();

  const [animation] = useState(new Animated.Value(1));
  const [recordingProgress, setRecordingProgress] = useState(0);

  useEffect(() => {
    if (isListening) {
      // Pulse animation while recording
      Animated.loop(
        Animated.sequence([
          Animated.timing(animation, { 
            toValue: 1.3, 
            duration: 800, 
            useNativeDriver: true 
          }),
          Animated.timing(animation, { 
            toValue: 1, 
            duration: 800, 
            useNativeDriver: true 
          }),
        ])
      ).start();

      // Progress animation (5 seconds)
      const progressInterval = setInterval(() => {
        setRecordingProgress(prev => {
          const newProgress = prev + 2; // 2% every 100ms = 5 seconds total
          if (newProgress >= 100) {
            clearInterval(progressInterval);
            return 100;
          }
          return newProgress;
        });
      }, 100);

      return () => {
        clearInterval(progressInterval);
      };
    } else {
      animation.setValue(1);
      setRecordingProgress(0);
    }
  }, [isListening, animation]);

  useEffect(() => {
    if (error) {
      onError(error);
    }
  }, [error, onError]);

  const handlePress = async () => {
    if (disabled || isListening) return;

    if (isExpoGo) {
      Alert.alert(
        'üö´ Expo Go Limitation',
        'Speech recognition c·∫ßn development build ƒë·ªÉ ho·∫°t ƒë·ªông.\n\nVui l√≤ng ch·∫°y:\n‚Ä¢ npx expo run:ios\n‚Ä¢ npx expo run:android\n\nho·∫∑c build th√†nh APK/IPA',
        [{ text: 'Hi·ªÉu r·ªìi' }]
      );
      return;
    }

    if (!isAvailable) {
      Alert.alert(
        'Kh√¥ng h·ªó tr·ª£',
        'Thi·∫øt b·ªã n√†y kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i',
        [{ text: 'OK' }]
      );
      return;
    }

    if (!hasPermission) {
      Alert.alert(
        'C·∫ßn quy·ªÅn truy c·∫≠p',
        '·ª®ng d·ª•ng c·∫ßn quy·ªÅn microphone ƒë·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i',
        [
          { text: 'H·ªßy', style: 'cancel' },
          { text: 'C√†i ƒë·∫∑t', onPress: checkAvailability }
        ]
      );
      return;
    }

    try {
      const config: NativeSpeechConfig = {
        language,
        maxResults: 5,
        continuous: false,
        partialResults: true
      };

      console.log('üéØ Expected text:', expectedText);
      const result = await recognizeForDuration(config, 5000);
      console.log('üéôÔ∏è Recognition result:', result);

      // Calculate accuracy
      const accuracy = calculateChineseAccuracy(result.transcript, expectedText);
      
      onResult({
        ...result,
        accuracy
      });

    } catch (err: any) {
      console.error('‚ùå Speech recognition failed:', err);
      onError(err.message || 'Nh·∫≠n di·ªán gi·ªçng n√≥i th·∫•t b·∫°i');
    }
  };

  const calculateChineseAccuracy = (spoken: string, expected: string): number => {
    if (!spoken || !expected) return 0;

    // Remove spaces and normalize
    const normalizeText = (text: string) => text.replace(/\s+/g, '').toLowerCase();
    const spokenNorm = normalizeText(spoken);
    const expectedNorm = normalizeText(expected);

    console.log('üìä Accuracy calculation:', { spoken: spokenNorm, expected: expectedNorm });

    // Character-level comparison for Chinese
    const spokenChars = Array.from(spokenNorm);
    const expectedChars = Array.from(expectedNorm);
    
    let matches = 0;
    const maxLength = Math.max(spokenChars.length, expectedChars.length);
    
    // Count exact character matches
    for (let i = 0; i < Math.min(spokenChars.length, expectedChars.length); i++) {
      if (spokenChars[i] === expectedChars[i]) {
        matches++;
      }
    }
    
    // Calculate accuracy with length penalty
    const accuracy = maxLength > 0 ? matches / maxLength : 0;
    console.log(`üéØ Accuracy: ${(accuracy * 100).toFixed(1)}% (${matches}/${maxLength} chars)`);
    
    return accuracy;
  };

  const getButtonStyle = () => {
    if (disabled) return [styles.button, styles.disabled];
    if (isExpoGo) return [styles.button, styles.expoGo];
    if (isListening) return [styles.button, styles.recording];
    return [styles.button, styles.ready];
  };

  const getButtonText = () => {
    if (disabled) return 'üö´ Kh√¥ng kh·∫£ d·ª•ng';
    if (isExpoGo) return '‚ö†Ô∏è C·∫ßn Development Build';
    if (isListening) return 'üéôÔ∏è ƒêang nghe...';
    if (!hasPermission) return 'üîí C·∫ßn quy·ªÅn truy c·∫≠p';
    if (!isAvailable) return '‚ùå Kh√¥ng h·ªó tr·ª£';
    return 'üé§ Nh·∫•n ƒë·ªÉ n√≥i';
  };

  const getStatusMessage = () => {
    if (isExpoGo) {
      return {
        title: '‚ö†Ô∏è Development Build Required',
        message: 'Speech recognition c·∫ßn development build ƒë·ªÉ ho·∫°t ƒë·ªông. Kh√¥ng th·ªÉ test trong Expo Go.',
        color: colors.secondary[500]
      };
    }
    if (!isAvailable) {
      return {
        title: '‚ùå Kh√¥ng kh·∫£ d·ª•ng',
        message: 'Speech recognition kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ tr√™n thi·∫øt b·ªã n√†y.',
        color: colors.error[500]
      };
    }
    if (!hasPermission) {
      return {
        title: 'üîí C·∫ßn quy·ªÅn truy c·∫≠p',
        message: 'Vui l√≤ng c·∫•p quy·ªÅn microphone v√† speech recognition.',
        color: colors.secondary[500]
      };
    }
    return null;
  };

  const statusMessage = getStatusMessage();

  return (
    <View style={styles.container}>
      <Animated.View style={[styles.buttonContainer, { transform: [{ scale: animation }] }]}>
        <TouchableOpacity
          style={getButtonStyle()}
          onPress={handlePress}
          disabled={disabled || isListening || !hasPermission || !isAvailable}
        >
          <Text style={styles.buttonText}>
            {getButtonText()}
          </Text>
          
          {isListening && (
            <View style={styles.progressContainer}>
              <View style={[styles.progressBar, { width: `${recordingProgress}%` }]} />
            </View>
          )}
        </TouchableOpacity>
      </Animated.View>
      
      {/* Status message for Expo Go or other issues */}
      {statusMessage && (
        <View style={[styles.statusMessageContainer, { borderLeftColor: statusMessage.color }]}>
          <Text style={[styles.statusTitle, { color: statusMessage.color }]}>
            {statusMessage.title}
          </Text>
          <Text style={styles.statusMessage}>
            {statusMessage.message}
          </Text>
          {isExpoGo && (
            <Text style={styles.statusInstructions}>
              ƒê·ªÉ test ch·ª©c nƒÉng n√†y:{'\n'}
              ‚Ä¢ npx expo run:ios{'\n'}
              ‚Ä¢ npx expo run:android
            </Text>
          )}
        </View>
      )}
      
      {/* Expected text display */}
      <View style={styles.expectedTextContainer}>
        <Text style={styles.expectedLabel}>H√£y n√≥i:</Text>
        <Text style={styles.expectedText}>{expectedText}</Text>
      </View>
      
      {/* Partial results display */}
      {(partialTranscript || transcript) && !isExpoGo && (
        <View style={styles.resultContainer}>
          <Text style={styles.resultLabel}>
            {isListening ? 'ƒêang nh·∫≠n di·ªán...' : 'K·∫øt qu·∫£:'}
          </Text>
          <Text style={styles.resultText}>
            {transcript || partialTranscript || '...'}
          </Text>
        </View>
      )}
      
      {/* Status indicators */}
      <View style={styles.statusContainer}>
        <StatusIndicator 
          label="Microphone" 
          status={hasPermission && !isExpoGo ? 'success' : 'error'} 
        />
        <StatusIndicator 
          label="Speech API" 
          status={isAvailable && !isExpoGo ? 'success' : 'error'} 
        />
        <StatusIndicator 
          label="Environment" 
          status={isExpoGo ? 'warning' : 'success'}
          value={isExpoGo ? 'Expo Go' : 'Dev Build'} 
        />
        <StatusIndicator 
          label="Language" 
          status="info" 
          value={language} 
        />
      </View>
    </View>
  );
};

// Status indicator component
const StatusIndicator: React.FC<{
  label: string;
  status: 'success' | 'error' | 'info' | 'warning';
  value?: string;
}> = ({ label, status, value }) => {
  const getStatusColor = () => {
    switch (status) {
      case 'success': return colors.accent[500];
      case 'error': return colors.error[500];
      case 'warning': return colors.secondary[500];
      case 'info': return colors.primary[500];
      default: return colors.neutral[400];
    }
  };

  const getStatusIcon = () => {
    switch (status) {
      case 'success': return '‚úÖ';
      case 'error': return '‚ùå';
      case 'warning': return '‚ö†Ô∏è';
      case 'info': return '‚ÑπÔ∏è';
      default: return '‚ö™';
    }
  };

  return (
    <View style={styles.statusItem}>
      <Text style={styles.statusIcon}>{getStatusIcon()}</Text>
      <Text style={styles.statusLabel}>{label}</Text>
      {value && <Text style={[styles.statusValue, { color: getStatusColor() }]}>{value}</Text>}
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    alignItems: 'center',
    paddingVertical: getResponsiveSpacing('lg'),
    paddingHorizontal: getResponsiveSpacing('md'),
  },
  
  buttonContainer: {
    marginBottom: getResponsiveSpacing('lg'),
  },
  
  button: {
    paddingVertical: getResponsiveSpacing('lg'),
    paddingHorizontal: getResponsiveSpacing('xl'),
    borderRadius: Layout.isMobile ? 25 : 30,
    minWidth: Layout.isMobile ? 200 : 250,
    minHeight: Layout.isMobile ? 60 : 70,
    alignItems: 'center',
    justifyContent: 'center',
    shadowColor: colors.neutral[900],
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.2,
    shadowRadius: 6,
    elevation: 6,
  },
  
  ready: {
    backgroundColor: colors.primary[500],
  },
  
  recording: {
    backgroundColor: colors.error[500],
  },
  
  disabled: {
    backgroundColor: colors.neutral[400],
  },

  expoGo: {
    backgroundColor: colors.secondary[500],
  },
  
  buttonText: {
    color: colors.neutral[50],
    fontSize: getResponsiveFontSize('base'),
    fontWeight: '600',
    textAlign: 'center',
  },
  
  progressContainer: {
    width: '100%',
    height: 4,
    backgroundColor: colors.neutral[200],
    borderRadius: 2,
    marginTop: getResponsiveSpacing('sm'),
    overflow: 'hidden',
  },
  
  progressBar: {
    height: '100%',
    backgroundColor: colors.neutral[50],
    borderRadius: 2,
  },

  statusMessageContainer: {
    backgroundColor: colors.neutral[50],
    padding: getResponsiveSpacing('lg'),
    borderRadius: Layout.isMobile ? 12 : 16,
    marginBottom: getResponsiveSpacing('md'),
    width: '100%',
    borderLeftWidth: 4,
  },

  statusTitle: {
    fontSize: getResponsiveFontSize('lg'),
    fontWeight: '600',
    marginBottom: getResponsiveSpacing('xs'),
  },

  statusMessage: {
    fontSize: getResponsiveFontSize('base'),
    color: colors.neutral[700],
    marginBottom: getResponsiveSpacing('xs'),
  },

  statusInstructions: {
    fontSize: getResponsiveFontSize('sm'),
    color: colors.neutral[600],
    fontFamily: 'monospace',
    backgroundColor: colors.neutral[100],
    padding: getResponsiveSpacing('sm'),
    borderRadius: 8,
  },
  
  expectedTextContainer: {
    backgroundColor: colors.neutral[100],
    padding: getResponsiveSpacing('md'),
    borderRadius: Layout.isMobile ? 12 : 16,
    marginBottom: getResponsiveSpacing('md'),
    width: '100%',
    alignItems: 'center',
  },
  
  expectedLabel: {
    fontSize: getResponsiveFontSize('sm'),
    color: colors.neutral[600],
    marginBottom: getResponsiveSpacing('xs'),
  },
  
  expectedText: {
    fontSize: getResponsiveFontSize('xl'),
    color: colors.neutral[900],
    fontWeight: '600',
    textAlign: 'center',
  },
  
  resultContainer: {
    backgroundColor: colors.accent[50],
    padding: getResponsiveSpacing('md'),
    borderRadius: Layout.isMobile ? 12 : 16,
    marginBottom: getResponsiveSpacing('md'),
    width: '100%',
    alignItems: 'center',
    borderLeftWidth: 4,
    borderLeftColor: colors.accent[500],
  },
  
  resultLabel: {
    fontSize: getResponsiveFontSize('sm'),
    color: colors.accent[700],
    marginBottom: getResponsiveSpacing('xs'),
  },
  
  resultText: {
    fontSize: getResponsiveFontSize('lg'),
    color: colors.accent[900],
    fontWeight: '500',
    textAlign: 'center',
  },
  
  statusContainer: {
    flexDirection: Layout.isMobile ? 'column' : 'row',
    gap: getResponsiveSpacing('sm'),
    width: '100%',
    justifyContent: 'center',
  },
  
  statusItem: {
    flexDirection: 'row',
    alignItems: 'center',
    gap: getResponsiveSpacing('xs'),
    paddingVertical: getResponsiveSpacing('xs'),
    paddingHorizontal: getResponsiveSpacing('sm'),
    backgroundColor: colors.neutral[50],
    borderRadius: 8,
    flex: Layout.isMobile ? 0 : 1,
  },
  
  statusIcon: {
    fontSize: 12,
  },
  
  statusLabel: {
    fontSize: getResponsiveFontSize('xs'),
    color: colors.neutral[600],
    flex: 1,
  },
  
  statusValue: {
    fontSize: getResponsiveFontSize('xs'),
    fontWeight: '600',
  },
});

export default NativeSpeechButton; 